{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __NB02 - Data Processing__\n",
    "\n",
    "**Objective:** This notebook processes and cleans the data collected from notebook 1 and filters the necessary data from the large V-Dem dataset. This data processing produce the following dataframes:\n",
    "\n",
    "- `vdem_filtered_df`\n",
    "- `worldbank_df`\n",
    "- `gdelt_df`\n",
    "\n",
    "These dataframes will then each be exported as tables into the `processed_data` database with SQLite3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "import json\n",
    "import functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Engine for SQL Database:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///../data/processed/processed_database.db', echo=False, isolation_level=\"AUTOCOMMIT\")\n",
    "with engine.connect() as conn:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extract the data from the V-Dem dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Read the V-Dem dataset as a `pandas` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w0/cyh7_1d94mx_ft1mfdkmbwrw0000gn/T/ipykernel_4371/2454491280.py:1: DtypeWarning: Columns (364,365,366,399,415,804,836,837,924,1240,1257,1486,3094,3168,3169,3341,3342,3344,3345,3347,3350,3352) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  vdem_df = pd.read_csv(\"../data/processed/V-Dem-CY-Full+Others-v14.csv\") # avoid printing the df as it is an extremely large dataset\n"
     ]
    }
   ],
   "source": [
    "vdem_df = pd.read_csv(\"../data/processed/V-Dem-CY-Full+Others-v14.csv\") # avoid printing the df as it is an extremely large dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Filter out the dataset to only contain data for the US, Brazil, India, Iran, France, and South Africa from 2014-2023 and for the following indicators:\n",
    "- `v2x_polyarchy` - electoral democracy index\n",
    "- `v2peapsecon` - access to public services distributed by socio-economic position\n",
    "- `v2pepwrses` - power distributed by socioeconomic position\n",
    "- `v2mecrit` - print/broadcast media critical\n",
    "- `v2cacamps` - political polairsation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_columns = ['country_name', 'country_text_id', 'year', 'v2x_polyarchy', 'v2peapsecon', 'v2pepwrses', 'v2mecrit', 'v2cacamps']\n",
    "\n",
    "required_countries = ['United States of America', 'Brazil', 'India', 'Iran', 'France', 'South Africa']\n",
    "\n",
    "vdem_filtered_df = vdem_df[\n",
    "    (vdem_df['year'] >= 2014) & \n",
    "    (vdem_df['year'] <= 2023) &\n",
    "    (vdem_df['country_name'].isin(required_countries))\n",
    "    ][interesting_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Change the `country_text_id` from ALPHA-3 to ALPHA-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdem_filtered_df['country_text_id'] = vdem_filtered_df['country_text_id'].str[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Add the V-Dem dataset to a database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 creating a table in the `processed_data.db` using SQLite for the vdem_filtered_df named `vdem_data`\n",
    "\n",
    "primary keys:\n",
    " - `country_id`\n",
    " - `year`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_statement_vdem = \"\"\"\n",
    "    CREATE TABLE vdem_data (\n",
    "        country_name CHAR(24),\n",
    "        country_text_id CHAR(2),\n",
    "        year INTEGER,\n",
    "        v2x_polyarchy REAL,\n",
    "        v2peapsecon REAL,\n",
    "        v2pepwrses REAL,\n",
    "        v2mecrit REAL,\n",
    "        v2cacamps REAL,\n",
    "        PRIMARY KEY (country_text_id, year)\n",
    "        );\n",
    "    \"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_statement_vdem))\n",
    "    vdem_filtered_df.to_sql(\"vdem_data\", conn, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Clean the World Bank dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 load all raw files and use pandas to concatinate them into one pandas dataframe which filters for the following columns: \n",
    "\n",
    "- `country_id` - country ID\n",
    "- `country_name` - the name of the country (US, Brazil, India, Iran, France, and South Africa)\n",
    "- `countryiso3code` - country code \n",
    "- `indicator.id` - indicator ID\n",
    "- `indicator.value` - name of indicator \n",
    "- `date` - in years (2014-2023)\n",
    "- `value` - numeric value of indictor \n",
    "- `unit` - unit of value \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"../data/raw/world_bank\"\n",
    "data_files = [os.path.join(data_directory, f) for f in os.listdir(data_directory) if f.endswith(\".json\")]\n",
    "worldbank_df = pd.concat((functions.process_file(file) for file in data_files), ignore_index=True)\n",
    "worldbank_df = worldbank_df.rename(columns={\n",
    "    'country.id': 'country_id',\n",
    "    'country.value': 'country_name',\n",
    "    'countryiso3code': 'iso3code',\n",
    "    'indicator.id': 'indicator_id',\n",
    "    'indicator.value': 'indicator_name',\n",
    "    'date': 'year',\n",
    "    'value': 'value',\n",
    "    'unit': 'unit'\n",
    "})[[\"country_id\", \"country_name\", \"iso3code\", \"indicator_id\", \"indicator_name\", \"year\", \"value\", \"unit\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 remove empty columns and ensure data types are appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldbank_df['year'] = pd.to_numeric(worldbank_df['year'], errors='coerce').astype('Int64')\n",
    "worldbank_df['value'] = pd.to_numeric(worldbank_df['value'], errors='coerce').astype(float) # Ensure 'value' is a float\n",
    "worldbank_df = worldbank_df.where(pd.notnull(worldbank_df), None)\n",
    "worldbank_df.drop_duplicates(inplace=True)\n",
    "worldbank_df.drop(columns=['unit'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Add the World Bank data to the database "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 creating a table in the `processed_data.db` using SQLite for the `worldbank_df` named `world_bank`\n",
    "\n",
    "primary keys:\n",
    " - `country_id`\n",
    " - `year`\n",
    " - `indicator_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_statement_world_bank = \"\"\"\n",
    "    CREATE TABLE world_bank (\n",
    "        country_id CHAR(2),\n",
    "        country_name CHAR(24),\n",
    "        iso3code CHAR(3),\n",
    "        indicator_id CHAR(50),\n",
    "        indicator_name CHAR(50),\n",
    "        year INTEGER,\n",
    "        value REAL,\n",
    "        PRIMARY KEY (country_id, year, indicator_id)\n",
    "        );\n",
    "    \"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_statement_world_bank))\n",
    "    worldbank_df.to_sql(\"world_bank\", conn, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create a Smaller GDELT dataset \n",
    "\n",
    "As the full GDELT data set is too large to load to a SQLite database or efficiently explore, we aggregated the data to improve its usability. \n",
    "instead of a column for each event, the final `gdelt_df` contains the following:\n",
    "- `country_code` and `year`: from the original data set\n",
    "- `event_code`: code categorizing a specific event-- see Notebook 1 for information on the codes' meanings  \n",
    "- `num_occurences`: number of corrences of each event code (per country, per year)\n",
    "- `num_mentions`: number of mentions in the press for each event code (per country, per year)\n",
    "- `avg_goldstein`, `min_goldstein`, `max_goldstein`: summary statistics for the golstein score (per event_code, per country, per year)\n",
    "- `avg_tone`, `min_tone`, `max_tone`: summary statistics for the tone of each event (per event_code, per country, per year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"../data/raw/gdelt\"\n",
    "gdelt_df = functions.process_gdelt_json(data_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Add Cleaned GDELT to the Data Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_statement_gdelt = \"\"\"\n",
    "    CREATE TABLE gdelt_events (\n",
    "        country_code CHAR(3),\n",
    "        year INTEGER,\n",
    "        EventCode INTEGER,\n",
    "        num_occurrences INTEGER,\n",
    "        num_mentions INTEGER,\n",
    "        avg_goldstein REAL,\n",
    "        min_goldstein REAL,\n",
    "        max_goldstein REAL,\n",
    "        avg_tone REAL,\n",
    "        min_tone REAL,\n",
    "        max_tone REAL,\n",
    "        PRIMARY KEY (country_code, year, EventCode)\n",
    "        );\n",
    "    \"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_statement_gdelt))\n",
    "    gdelt_df.to_sql(\"gdelt_events\", conn, if_exists=\"append\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
